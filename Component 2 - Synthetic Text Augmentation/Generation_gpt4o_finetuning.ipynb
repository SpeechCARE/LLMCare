{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries + Requirements\n",
    "This cell imports all required libraries and initializes the OpenAI client.\n",
    "\n",
    "Run this cell first to prepare the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "model_name = 'gpt-4o-2024-11-20'\n",
    "api_key = 'YOUR_API_KEY' #rs_user_description\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "label_map = {0:'Healthy', 1:'AD'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant \n",
    "\n",
    "This cell sets the locations of training/validation/test datasets and builds prompt templates used for synthetic text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System instruction for chat template\n",
    "\n",
    "label_mapping_dict = {0: \"Healthy\", 1: \"ADRD\"}\n",
    "\n",
    "root_dir = '/workspace/'\n",
    "data_dir = root_dir\n",
    "pred_dir = root_dir + 'predictions/'\n",
    "train_dataset_path = data_dir + 'train.csv'\n",
    "valid_dataset_path = data_dir + 'validation.csv'\n",
    "test_dataset_path = data_dir + 'Test_DePiC.xlsx'\n",
    "\n",
    "\n",
    "label_mapping_dict = {0: \"Healthy\", 1: \"ADRD\"}\n",
    "\n",
    "# System instruction for chat template\n",
    "generation_system_prompt = \"\"\"You are an expert cognitive impairment analyst.\n",
    "Your role is to generate spoken language transcripts based on linguistic patterns.\n",
    "\"\"\"\n",
    "generation_task_prompts =[ (\n",
    "\"As a language and cognition specialist, generate a realistic spoken monologue of someone describing the “Cookie Theft” image.\"\n",
    "\"\\nHealthy: Include advanced sentence structures, precise vocabulary, and an organized depiction of the scene.\"\n",
    "\"\\nADRD: Include repeated segments, stumbling or halting speech, misplaced words, and sentence fragments.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\"You are a neurocognitive researcher studying everyday speech. Craft a spoken-style transcript of a person talking about the “Cookie Theft” image.\"\n",
    "\"\\nHealthy: Show natural fluency, clear reference to the main elements in the picture, and cohesive transitions.\"\n",
    "\"\\nADRD: Show echoes of previous statements, grammatical mishaps, filler words, and abrupt topic shifts.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\"You are an expert in cognitive assessments for older adults. Provide a natural, conversational transcript of a person describing the “Cookie Theft” picture.\"\n",
    "\"\\nHealthy: Use elaborate syntax, coherent progress from one detail to another, and minimal disfluencies.\"\n",
    "\"\\nADRD: Use frequent filler words (“you know,” “like”), disjointed or incomplete clauses, and noticeable grammatical errors.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\n",
    "\"As a specialist in cognitive health and communication, produce a brief, spoken-style transcript of someone describing the “Cookie Theft” image.\"\n",
    "\"\\nHealthy: Expect detailed observation, fluid speech, and well-formed sentences.\"\n",
    "\"\\nADRD: Expect word-finding pauses, repetition of concepts, grammatical inconsistencies, and less organized content.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\n",
    "\"You are an advanced language model trained in speech analysis for cognitive health. Create a spontaneous-soundingexplanation of the “Cookie Theft” picture.\"\n",
    "\"\\nHealthy: Demonstrate complex grammatical structures, coherent narrative flow, and smooth connectivity.\"\n",
    "\"\\nADRD: Demonstrate repeated attempts at words, filler phrases, sentence fragments, and reduced coherence\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\n",
    "\"As a researcher in cognitive-linguistic assessment, generate a spoken language transcript of an individual describing the “Cookie Theft” image. Keep it natural and unrehearsed.\"\n",
    "\"\\nHealthy: Incorporate sophisticated syntax, purposeful word choice, and a clear storyline.\"\n",
    "\"\\nADRD: Include repetitions, stumbling over words, run-on or abruptly cut-off sentences, and difficulty finding the right words.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\n",
    "\"You are an expert in geriatric neuropsychology. Produce a short, speech-like narration of a person describing the “Cookie Theft” picture.\"\n",
    "\"\\nHealthy: Look for varied vocabulary, coherent transitions, and overall fluency.\"\n",
    "\"\\nADRD: Capture frequent pauses, filler utterances (“um,” “uh”), grammatical mistakes, and incomplete thoughts.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\n",
    "\"Act as a clinician studying language use in older adults. Generate a spoken transcript of someone describing the “Cookie Theft” scenario as if they’re talking naturally (not reading prepared text).\"\n",
    "\"\\nHealthy: Emphasize complex syntax, detailed description, and logical flow.\"\n",
    "\"\\nADRD: Emphasize repeated words, hesitations, grammar errors, and disjointed phrases.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\n",
    "\"You are a specialized speech-language pathologist focusing on cognitive health. Please create a short, spontaneous-sounding transcript of an individual describing the “Cookie Theft” picture.\"\n",
    "\"\\nFor Healthy: Observe intricate sentence structure, clear semantics, fluent delivery, and coherent storytelling.\"\n",
    "\"\\nFor ADRD: Pay attention to repeating phrases, filler words, noticeable grammatical slips, fragmented sentences, and disfluencies.\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    "),\n",
    "(\n",
    "\"You are a recognized expert in geriatric language assessment. Create a short, unpolished spoken transcript of a person explaining what they see in the “Cookie Theft” image.\"\n",
    "\"\\nHealthy: Characterize fluid sentences, organized thoughts, and diverse vocabulary.\"\n",
    "\"\\nADRD: Characterize repeated or circular phrasing, noticeable disfluencies, incomplete ideas, and filler expressions\"\n",
    "\"\\nLabel: {label}\"\n",
    "\"\\ntext:\"\n",
    ")\n",
    "]\n",
    "\n",
    "Inference_prompts = [(\n",
    "    \"You are an expert in cognitive health and language analysis. You will generate a spoken language transcript of a person describing the 'Cookie Theft' picture. This should reflect spontaneous speech rather than formal written text. Generate a text based on the given label.\"\n",
    "    \"\\nLabel: {label}\"\n",
    "    \"\\ntext:\"\n",
    ")]\n",
    "\n",
    "\n",
    "train_data_path = './Data/train.csv'\n",
    "valid_data_path = './Data/validation.csv'\n",
    "test_data_path = './Data/Test_DePiC.xlsx'\n",
    "\n",
    "train_out_file = './Data/train_prompt.jsonl'\n",
    "valid_out_file = './Data/valid_prompt.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility: Convert dataset into JSONL format\n",
    "This function takes a DataFrame, wraps each row into a structured  chat-style format (system, user, assistant), and saves it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(data, output_file_path):\n",
    "    jsonl_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        selected_prompt = random.choice(generation_task_prompts)\n",
    "        prompt = selected_prompt.format(label=label_mapping_dict[row[\"label\"]])\n",
    "        jsonl_data.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": generation_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "                {\"role\": \"assistant\", \"content\": str(row['text'])}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    # Save to JSONL format\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for item in jsonl_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    return jsonl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads CSV datasets, applies the JSONL conversion function, and generates training/validation prompt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_path)\n",
    "valid_df = pd.read_csv(valid_data_path)\n",
    "\n",
    "train_data = save_to_jsonl(train_df, train_out_file)\n",
    "valid_data = save_to_jsonl(valid_df, valid_out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Validate dataset format\n",
    "This function ensures the JSONL files have the correct structure:\n",
    "\n",
    "- Messages contain role and content\n",
    "- Assistant responses are present\n",
    "- No unrecognized keys\n",
    "\n",
    "Run this after dataset preparation to confirm integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(dataset):\n",
    "    # Format error checks\n",
    "    format_errors = defaultdict(int)\n",
    "\n",
    "    for ex in dataset:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "            \n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "            \n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "            \n",
    "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "            \n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "                \n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "            \n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "        \n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "    if format_errors:\n",
    "        print(\"Found errors:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"No errors found\")\n",
    "        \n",
    "        \n",
    "check_data(train_data)\n",
    "check_data(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = client.files.create(\n",
    "  file=open(train_out_file, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "valid_file = client.files.create(\n",
    "  file=open(valid_out_file, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"Training file Info: {train_file}\")\n",
    "print(f\"Validation file Info: {valid_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = client.files.retrieve('FILE_ID')\n",
    "valid_file = client.files.retrieve('FILE_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creat Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train2 - LR multiplier = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.fine_tuning.jobs.create(\n",
    "  training_file=train_file.id, \n",
    "  validation_file=valid_file.id,\n",
    "  model=\"gpt-4o-2024-08-06\", \n",
    "  hyperparameters={\n",
    "    \"n_epochs\": 3,\n",
    "\t\"batch_size\": 16,\n",
    "\t\"learning_rate_multiplier\": 2.5\n",
    "  }\n",
    ")\n",
    "job_id = model.id\n",
    "status = model.status\n",
    "\n",
    "print(f'Fine-tuning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {model}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(job_id).status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train2 - LR Multiplier = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_tuned_model_id = client.fine_tuning.jobs.retrieve(job_id).fine_tuned_model\n",
    "print(f'model id: {generation_tuned_model_id}')\n",
    "print(client.fine_tuning.jobs.retrieve(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_results = client.fine_tuning.jobs.retrieve(job_id).result_files\n",
    "result_file = client.files.retrieve(fine_tune_results[0])\n",
    "content = client.files.content(result_file.id)\n",
    "import base64\n",
    "base64.b64decode(content.text.encode('utf-8'))\n",
    "with open('./Data/gptFinetuning_results_first_prompt.csv', 'wb') as f:\n",
    "    f.write(base64.b64decode(content.text.encode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train2 - LR Multiplier=2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chck_point = 'YOUR_CHECKPOINT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoin_list = client.fine_tuning.jobs.checkpoints.list(chck_point)\n",
    "# print(model_checkpoin_list)\n",
    "checkpoint_names = []\n",
    "for chckpnt in model_checkpoin_list:\n",
    "    print(f'model id: {chckpnt.id}')\n",
    "    print(f'model name: {chckpnt.fine_tuned_model_checkpoint}')\n",
    "    checkpoint_names.append(chckpnt.fine_tuned_model_checkpoint)\n",
    "    print(f'step number: {chckpnt.step_number}')\n",
    "    print(f'valid loss: {chckpnt.metrics.full_valid_loss}')\n",
    "    print(f'valid accuracy: {chckpnt.metrics.full_valid_mean_token_accuracy}')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(system_message, user_instruction):\n",
    "    chat_response = client.chat.completions.create(\n",
    "    model=model_name, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_instruction},\n",
    "    ],\n",
    "    max_completion_tokens=350,\n",
    "    temperature=1,\n",
    "    # top_p=0.95,\n",
    "    )\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "def inference_tuned_model(model_id, data, save_path):\n",
    "    pred_texts = []\n",
    "    for j in range(0, aug_count):\n",
    "        for i, row in tqdm(data.iterrows()):\n",
    "            prompt = Inference_prompts[0].format(label=label_mapping_dict[row['label']])\n",
    "            pred_text = chat_with_llm(generation_system_prompt, prompt)\n",
    "            pred_texts.append((int(row['label']), pred_text))\n",
    "\n",
    "    df = pd.DataFrame(pred_texts, columns=[\"label\", \"text\"])\n",
    "    df.to_excel(save_path, index=False)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_count = 1\n",
    "for i, chkpnt in enumerate(checkpoint_names):\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    modif_train_data = inference_tuned_model(chkpnt, train_data, f\"./Data/gpt4_temp1_two_aug_step{i}.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
